{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1. Обучить модель на понравившихся данных\n",
    "2. Создать rest api сервис, к которому можно будет обращаться для получения прогнозов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примерные темы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Определение токсичности комментария\n",
    "2. Определение стоимости жилья от разных факторов: площадь жилья, удаленность от центра, etc (здесь же куча идей прогнозирования стоимости чего-либо по его описанию)\n",
    "3. Темы новости по ее тексту\n",
    "4. Классификатор рукописных цифр\n",
    "5. Классификатор картинок (например, определение города и страны по снимку улицы)\n",
    "6. Определение вероятности наличия сердечно-сосудистых заболеваний по данным первичного осмотра (или что-то подобное)\n",
    "7. Многое другое (придумайте сами)\n",
    "8. Прогнозирование рейтинга вопроса на stackoverflow - https://www.kaggle.com/imoore/60k-stack-overflow-questions-with-quality-rate\n",
    "9. https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016\n",
    "10. Тематическое моделирование статей на arxiv - https://www.kaggle.com/Cornell-University/arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Откуда брать данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. kaggle (https://www.kaggle.com/datasets)\n",
    "2. спарсить самостоятельно, но в этом случае вам может понадобиться разметка (если у вас обучение с учителем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import dill\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, classification_report, precision_recall_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    root_dir = \"../datasets/kaggle_datasets/pulsar_data/\"\n",
    "    seed = 21\n",
    "\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]\n",
    "    \n",
    "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        self.columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.get_dummies(X, prefix=self.key)\n",
    "        test_columns = [col for col in X.columns]\n",
    "        for col_ in test_columns:\n",
    "            if col_ not in self.columns:\n",
    "                X[col_] = 0\n",
    "        return X[self.columns]\n",
    "    \n",
    "\n",
    "def get_metrics(y_test, probs, fstr=True):\n",
    "    \"\"\"\n",
    "    Функция перехода от вероятностей к меткам классов.\n",
    "    Для этого нужно подобрать порог - Best_Threshold={thresholds[ix]:.3f},\n",
    "    после которого мы считаем,\n",
    "    что объект можно отнести к классу 1 \n",
    "    (если вероятность больше порога -\n",
    "    размечаем объект как класс 1,\n",
    "    если нет - класс 0)\n",
    "\n",
    "    Args:\n",
    "        y_test ([type]): [Истинные классы]\n",
    "        probs ([type]): [Предсказанные вероятности принадлежности к классу]\n",
    "        fstr (bool, optional): [флаг вывода]. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        if fstr is True:\n",
    "            [f'str']: [Выводиться f-string в виде: \n",
    "                        f'Best_Threshold={thresholds[ix]:.3f},\\n'\n",
    "                        f'F_Score={fscore[ix]:.3f},\\n'\n",
    "                        f'Precision={precision[ix]:.3f},\\n'\n",
    "                        f'Recall={recall[ix]:.3f},\\n'\n",
    "                        f'Roc_AUC={roc_auc_score(y_test, probs)}']\n",
    "        else:\n",
    "            [tuple]: [(\n",
    "                       thresholds[ix]: float,\n",
    "                       fscore[ix]: float,\n",
    "                       precision[ix]: float,\n",
    "                       recall[ix]: float,\n",
    "                       roc_auc_score(y_test, probs): float\n",
    "                       )]\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    roc = roc_auc_score(y_test, probs)\n",
    "    ix = np.argmax(fscore)\n",
    "    if fstr:\n",
    "        return(f'Best_Threshold:\\t{thresholds[ix]:.3f},\\n'\n",
    "               f'F1_Score:\\t{(fscore[ix]*100.0):.3f}%,\\n'\n",
    "               f'Roc_AUC:\\t{(roc*100.0):.3f}%,\\n'\n",
    "               f'Precision:\\t{(precision[ix]*100.0):.3f}%,\\n'\n",
    "               f'Recall: \\t{(recall[ix]*100.0):.3f}%')\n",
    "    else:\n",
    "        return thresholds[ix], fscore[ix], roc, precision[ix], recall[ix]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{Config.root_dir}pulsar_data_train.csv\")\n",
    "test_df = pd.read_csv(f\"{Config.root_dir}pulsar_data_test.csv\")\n",
    "target = train_df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([' Mean of the integrated profile',\n",
       "        ' Standard deviation of the integrated profile',\n",
       "        ' Excess kurtosis of the integrated profile',\n",
       "        ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',\n",
       "        ' Standard deviation of the DM-SNR curve',\n",
       "        ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve',\n",
       "        'target_class'],\n",
       "       dtype='object'),\n",
       " Index([' Mean of the integrated profile',\n",
       "        ' Standard deviation of the integrated profile',\n",
       "        ' Excess kurtosis of the integrated profile',\n",
       "        ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',\n",
       "        ' Standard deviation of the DM-SNR curve',\n",
       "        ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve',\n",
       "        'target_class'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Наблюдаются неудобные пробелы перед именами колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.columns = map(str.strip, train_df.columns.to_list())\n",
    "test_df.columns = map(str.strip, test_df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Mean of the integrated profile',\n",
       "        'Standard deviation of the integrated profile',\n",
       "        'Excess kurtosis of the integrated profile',\n",
       "        'Skewness of the integrated profile', 'Mean of the DM-SNR curve',\n",
       "        'Standard deviation of the DM-SNR curve',\n",
       "        'Excess kurtosis of the DM-SNR curve', 'Skewness of the DM-SNR curve',\n",
       "        'target_class'],\n",
       "       dtype='object'),\n",
       " Index(['Mean of the integrated profile',\n",
       "        'Standard deviation of the integrated profile',\n",
       "        'Excess kurtosis of the integrated profile',\n",
       "        'Skewness of the integrated profile', 'Mean of the DM-SNR curve',\n",
       "        'Standard deviation of the DM-SNR curve',\n",
       "        'Excess kurtosis of the DM-SNR curve', 'Skewness of the DM-SNR curve',\n",
       "        'target_class'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12528 entries, 0 to 12527\n",
      "Data columns (total 9 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   Mean of the integrated profile                12528 non-null  float64\n",
      " 1   Standard deviation of the integrated profile  12528 non-null  float64\n",
      " 2   Excess kurtosis of the integrated profile     10793 non-null  float64\n",
      " 3   Skewness of the integrated profile            12528 non-null  float64\n",
      " 4   Mean of the DM-SNR curve                      12528 non-null  float64\n",
      " 5   Standard deviation of the DM-SNR curve        11350 non-null  float64\n",
      " 6   Excess kurtosis of the DM-SNR curve           12528 non-null  float64\n",
      " 7   Skewness of the DM-SNR curve                  11903 non-null  float64\n",
      " 8   target_class                                  12528 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 881.0 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка наличия пропусклов в одинаковых столбцах "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().any().to_list()[:-1] == test_df.isnull().any().to_list()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mean of the integrated profile                     0\n",
       "Standard deviation of the integrated profile       0\n",
       "Excess kurtosis of the integrated profile       1735\n",
       "Skewness of the integrated profile                 0\n",
       "Mean of the DM-SNR curve                           0\n",
       "Standard deviation of the DM-SNR curve          1178\n",
       "Excess kurtosis of the DM-SNR curve                0\n",
       "Skewness of the DM-SNR curve                     625\n",
       "target_class                                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(train_df).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропущенных значений на среднее значение по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.fillna(train_df.mean(axis=0), inplace=True)\n",
    "test_df.fillna(test_df.mean(axis=0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mean of the integrated profile                  0\n",
       " Standard deviation of the integrated profile    0\n",
       " Excess kurtosis of the integrated profile       0\n",
       " Skewness of the integrated profile              0\n",
       " Mean of the DM-SNR curve                        0\n",
       " Standard deviation of the DM-SNR curve          0\n",
       " Excess kurtosis of the DM-SNR curve             0\n",
       " Skewness of the DM-SNR curve                    0\n",
       " target_class                                    0\n",
       " dtype: int64,\n",
       " Mean of the integrated profile                     0\n",
       " Standard deviation of the integrated profile       0\n",
       " Excess kurtosis of the integrated profile          0\n",
       " Skewness of the integrated profile                 0\n",
       " Mean of the DM-SNR curve                           0\n",
       " Standard deviation of the DM-SNR curve             0\n",
       " Excess kurtosis of the DM-SNR curve                0\n",
       " Skewness of the DM-SNR curve                       0\n",
       " target_class                                    5370\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(train_df).sum(), np.isnan(test_df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target_class'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mean of the integrated profile',\n",
       " 'Standard deviation of the integrated profile',\n",
       " 'Excess kurtosis of the integrated profile',\n",
       " 'Skewness of the integrated profile',\n",
       " 'Mean of the DM-SNR curve',\n",
       " 'Standard deviation of the DM-SNR curve',\n",
       " 'Excess kurtosis of the DM-SNR curve',\n",
       " 'Skewness of the DM-SNR curve']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = train_df.columns.to_list()[:-1]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[features], train_df[target], test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = features.copy()\n",
    "final_transformers = list()\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))\n",
    "    \n",
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', xgb.XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Mean of the integrated '\n",
       "                                                 'profile',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Mean '\n",
       "                                                                                     'of '\n",
       "                                                                                     'the '\n",
       "                                                                                     'integrated '\n",
       "                                                                                     'profile')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('Standard deviation of the '\n",
       "                                                 'integrated profile',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Standard '\n",
       "                                                                                     'deviation '\n",
       "                                                                                     'of '\n",
       "                                                                                     'the '\n",
       "                                                                                     'integrated '\n",
       "                                                                                     'profile...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mean of the integrated profile',\n",
       "       'Standard deviation of the integrated profile',\n",
       "       'Excess kurtosis of the integrated profile',\n",
       "       'Skewness of the integrated profile', 'Mean of the DM-SNR curve',\n",
       "       'Standard deviation of the DM-SNR curve',\n",
       "       'Excess kurtosis of the DM-SNR curve', 'Skewness of the DM-SNR curve'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Threshold:\t0.200,\n",
      "F1_Score:\t86.707%,\n",
      "Roc_AUC:\t97.076%,\n",
      "Precision:\t88.037%,\n",
      "Recall: \t85.417%\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics(y_test, y_pred_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Excess kurtosis of the integrated profile</th>\n",
       "      <td>0.566222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skewness of the integrated profile</th>\n",
       "      <td>0.140101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean of the integrated profile</th>\n",
       "      <td>0.063153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           coefficient\n",
       "Excess kurtosis of the integrated profile     0.566222\n",
       "Skewness of the integrated profile            0.140101\n",
       "Mean of the integrated profile                0.063153"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_features = pd.DataFrame(pipeline[1].feature_importances_, \n",
    "                        continuous_columns, \n",
    "                        columns=['coefficient'])\n",
    "features_important = xgb_features.sort_values('coefficient', ascending=False).head(3)\n",
    "features_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excess kurtosis of the integrated profile',\n",
       " 'Skewness of the integrated profile',\n",
       " 'Mean of the integrated profile']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_important.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns = features_important.index.to_list().copy()\n",
    "final_transformers = list()\n",
    "    \n",
    "for cont_col in continuous_columns:\n",
    "    cont_transformer = Pipeline([\n",
    "                ('selector', NumberSelector(key=cont_col)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ])\n",
    "    final_transformers.append((cont_col, cont_transformer))\n",
    "    \n",
    "feats = FeatureUnion(final_transformers)\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features',feats),\n",
    "    ('classifier', xgb.XGBClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programming\\anaconda3\\lib\\site-packages\\xgboost-1.4.1-py3.8-win-amd64.egg\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('Excess kurtosis of the '\n",
       "                                                 'integrated profile',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Excess '\n",
       "                                                                                     'kurtosis '\n",
       "                                                                                     'of '\n",
       "                                                                                     'the '\n",
       "                                                                                     'integrated '\n",
       "                                                                                     'profile')),\n",
       "                                                                 ('scaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('Skewness of the integrated '\n",
       "                                                 'profile',\n",
       "                                                 Pipeline(steps=[('selector',\n",
       "                                                                  NumberSelector(key='Skewness '\n",
       "                                                                                     'of '\n",
       "                                                                                     'the '\n",
       "                                                                                     'integrated '\n",
       "                                                                                     'profi...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best_Threshold:\t0.350,\n",
      "F1_Score:\t85.231%,\n",
      "Roc_AUC:\t95.875%,\n",
      "Precision:\t88.217%,\n",
      "Recall: \t82.440%\n"
     ]
    }
   ],
   "source": [
    "print(get_metrics(y_test, y_pred_proba[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pulsar_model.dill\", \"wb\") as f:\n",
    "    dill.dump(pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pulsar_model.dill\", 'rb') as f:\n",
    "\t\tmodel = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Excess_kurtosis_of_the_integrated_profile = -0.234571\n",
    "Skewness_of_the_integrated_profile = -0.699648\n",
    "Mean_of_the_integrated_profile = 140.562500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.predict_proba(pd.DataFrame({\"Excess kurtosis of the integrated profile\": [Excess_kurtosis_of_the_integrated_profile],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  \"Skewness of the integrated profile\": [Skewness_of_the_integrated_profile],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t  'Mean of the integrated profile': [Mean_of_the_integrated_profile],}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.994132e-01, 5.867855e-04]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-May-30 13:57:58] Data: description=1, company_profile=1, benefits=1\n"
     ]
    }
   ],
   "source": [
    "from time import strftime\n",
    "description=1\n",
    "company_profile=1\n",
    "benefits=1\n",
    "dt = strftime(\"[%Y-%b-%d %H:%M:%S]\")\n",
    "print(f'{dt} Data: description={description}, company_profile={company_profile}, benefits={benefits}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
